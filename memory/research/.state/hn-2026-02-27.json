[
  {
    "_highlightResult": {
      "author": {
        "matchLevel": "none",
        "matchedWords": [],
        "value": "subh10"
      },
      "story_text": {
        "matchLevel": "none",
        "matchedWords": [],
        "value": "Hey HN,<p>We’re the team behind Bestsys &amp; Maven AI Agents. We believe the future of work isn’t just AI-assisted—it’s AI-driven. Today, businesses spend over $500B annually on outsourcing repetitive work (finance, HR, customer support, data entry). We built Maven AI Agents to replace human-driven outsourcing with autonomous AI workers that learn, execute, and improve over time.<p>How It Works:\nMaven AI Agents learn workflows by observing human employees.\nThey autonomously execute tasks with near-human accuracy and 24/7 availability.\nUnlike RPA or AI assistants, they don’t just assist—they replace entire teams.\nWhy Now?\nBusinesses are realizing generic AI isn’t enough—they need company-trained AI workers.\nThe shift from SaaS (tools) to SaaS 2.0 (autonomous execution) is happening now.\nAdvances in LLMs &amp; multi-agent AI enable scalable, company-specific automation.\nTraction So Far\n25+ companies onboarded\nAI agents improving at 64% efficiency per month\nAutomating finance, HR, and customer workflows for real businesses\nPreparing for multi-tenancy &amp; SaaS launch\nWhat’s Next?\nWe’re scaling quickly and looking for feedback from developers, AI researchers, and startup founders. If you’re building in the AI automation space, we’d love to hear your thoughts.<p>→ Try Bestsys (early access): Bestsys.co<p>What do you think about AI replacing human outsourcing?"
      },
      "title": {
        "matchLevel": "none",
        "matchedWords": [],
        "value": "We Built AI Agents That Replace Outsourcing Firms (Live with 25 Companies)"
      }
    },
    "_tags": [
      "story",
      "author_subh10",
      "story_43227853",
      "ask_hn"
    ],
    "author": "subh10",
    "children": [
      43227888,
      43227896,
      43228049,
      43229942
    ],
    "created_at": "2025-03-02T06:05:04Z",
    "created_at_i": 1740895504,
    "num_comments": 4,
    "objectID": "43227853",
    "points": 5,
    "story_id": 43227853,
    "story_text": "Hey HN,<p>We’re the team behind Bestsys &amp; Maven AI Agents. We believe the future of work isn’t just AI-assisted—it’s AI-driven. Today, businesses spend over $500B annually on outsourcing repetitive work (finance, HR, customer support, data entry). We built Maven AI Agents to replace human-driven outsourcing with autonomous AI workers that learn, execute, and improve over time.<p>How It Works:\nMaven AI Agents learn workflows by observing human employees.\nThey autonomously execute tasks with near-human accuracy and 24&#x2F;7 availability.\nUnlike RPA or AI assistants, they don’t just assist—they replace entire teams.\nWhy Now?\nBusinesses are realizing generic AI isn’t enough—they need company-trained AI workers.\nThe shift from SaaS (tools) to SaaS 2.0 (autonomous execution) is happening now.\nAdvances in LLMs &amp; multi-agent AI enable scalable, company-specific automation.\nTraction So Far\n25+ companies onboarded\nAI agents improving at 64% efficiency per month\nAutomating finance, HR, and customer workflows for real businesses\nPreparing for multi-tenancy &amp; SaaS launch\nWhat’s Next?\nWe’re scaling quickly and looking for feedback from developers, AI researchers, and startup founders. If you’re building in the AI automation space, we’d love to hear your thoughts.<p>→ Try Bestsys (early access): Bestsys.co<p>What do you think about AI replacing human outsourcing?",
    "title": "We Built AI Agents That Replace Outsourcing Firms (Live with 25 Companies)",
    "updated_at": "2025-03-04T07:01:58Z",
    "url": "",
    "hn_url": "https://news.ycombinator.com/item?id=43227853",
    "comments": 4,
    "query": "AI agents business execution",
    "score": 9
  },
  {
    "_highlightResult": {
      "author": {
        "matchLevel": "none",
        "matchedWords": [],
        "value": "edunteman"
      },
      "story_text": {
        "fullyHighlighted": false,
        "matchLevel": "full",
        "matchedWords": [
          "ai",
          "agents",
          "business",
          "execution"
        ],
        "value": "Hi HN! Erik here from Pig.dev, and today I'd like to share a new project we've just open sourced:<p>Muscle Mem is an SDK that records your <em>agent's</em> tool-calling patterns as it solves tasks, and will deterministically replay those learned trajectories whenever the task is encountered again, falling back to agent mode if edge cases are detected. Like a JIT compiler, for behaviors.<p>At Pig, we built computer-use <em>agents</em> for automating legacy Windows applications (healthcare, lending, manufacturing, etc).<p>A recurring theme we ran into was that <em>businesses</em> <i>already</i> had RPA (pure-software scripts), and it worked for them in most cases. The pull to <em>agents</em> as an RPA alternative was <i>not</i> to have an infinitely flexible &quot;<em>AI</em> Employees&quot; as tech Twitter/X may want you to think, but simply because their RPA breaks under occasional edge-cases and <em>agents</em> can gracefully handle those cases.<p>Using a pure-agent approach proved to be highly wasteful. Window's accessibility APIs are poor, so you're generally stuck using pure-vision <em>agents</em>, which can run around $40/hr in token costs and take 5x longer than a human to perform a workflow. At this point, you're better off hiring a human.<p>The goal of Muscle-Mem is to get LLMs out of the hot path of repetitive automations, intelligently swapping between script-based <em>execution</em> for repeat cases, and agent-based automations for discovery and self-healing.<p>While inspired by computer-use environments, Muscle Mem is designed to generalize to any automation performing discrete tasks in dynamic environments. It took a great deal of thought to figure out an API that generalizes, which I cover more deeply in this blog:\n<a href=\"https://erikdunteman.com/blog/muscle-mem/\" rel=\"nofollow\">https://erikdunteman.com/blog/muscle-mem/</a><p>Check out the repo, consider giving it a star, or dive deeper into the above blog. I look forward to your feedback!"
      },
      "title": {
        "fullyHighlighted": false,
        "matchLevel": "partial",
        "matchedWords": [
          "ai",
          "agents"
        ],
        "value": "Show HN: Muscle-Mem, a behavior cache for <em>AI</em> <em>agents</em>"
      },
      "url": {
        "matchLevel": "none",
        "matchedWords": [],
        "value": "https://github.com/pig-dot-dev/muscle-mem"
      }
    },
    "_tags": [
      "story",
      "author_edunteman",
      "story_43988381",
      "show_hn"
    ],
    "author": "edunteman",
    "children": [
      43991197,
      43989752,
      43988789,
      43992832,
      43990420,
      43989430,
      43988590,
      43989033,
      43989862,
      43989464,
      43991632,
      43994379,
      43991958,
      43989416,
      43990883,
      43989296,
      43989110,
      43988980,
      43992034,
      43989382,
      43990185,
      43992435,
      43994344
    ],
    "created_at": "2025-05-14T19:38:26Z",
    "created_at_i": 1747251506,
    "num_comments": 51,
    "objectID": "43988381",
    "points": 226,
    "story_id": 43988381,
    "story_text": "Hi HN! Erik here from Pig.dev, and today I&#x27;d like to share a new project we&#x27;ve just open sourced:<p>Muscle Mem is an SDK that records your agent&#x27;s tool-calling patterns as it solves tasks, and will deterministically replay those learned trajectories whenever the task is encountered again, falling back to agent mode if edge cases are detected. Like a JIT compiler, for behaviors.<p>At Pig, we built computer-use agents for automating legacy Windows applications (healthcare, lending, manufacturing, etc).<p>A recurring theme we ran into was that businesses <i>already</i> had RPA (pure-software scripts), and it worked for them in most cases. The pull to agents as an RPA alternative was <i>not</i> to have an infinitely flexible &quot;AI Employees&quot; as tech Twitter&#x2F;X may want you to think, but simply because their RPA breaks under occasional edge-cases and agents can gracefully handle those cases.<p>Using a pure-agent approach proved to be highly wasteful. Window&#x27;s accessibility APIs are poor, so you&#x27;re generally stuck using pure-vision agents, which can run around $40&#x2F;hr in token costs and take 5x longer than a human to perform a workflow. At this point, you&#x27;re better off hiring a human.<p>The goal of Muscle-Mem is to get LLMs out of the hot path of repetitive automations, intelligently swapping between script-based execution for repeat cases, and agent-based automations for discovery and self-healing.<p>While inspired by computer-use environments, Muscle Mem is designed to generalize to any automation performing discrete tasks in dynamic environments. It took a great deal of thought to figure out an API that generalizes, which I cover more deeply in this blog:\n<a href=\"https:&#x2F;&#x2F;erikdunteman.com&#x2F;blog&#x2F;muscle-mem&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;erikdunteman.com&#x2F;blog&#x2F;muscle-mem&#x2F;</a><p>Check out the repo, consider giving it a star, or dive deeper into the above blog. I look forward to your feedback!",
    "title": "Show HN: Muscle-Mem, a behavior cache for AI agents",
    "updated_at": "2025-10-29T05:50:06Z",
    "url": "https://github.com/pig-dot-dev/muscle-mem",
    "hn_url": "https://news.ycombinator.com/item?id=43988381",
    "comments": 51,
    "query": "AI agents business execution",
    "score": 277
  },
  {
    "_highlightResult": {
      "author": {
        "matchLevel": "none",
        "matchedWords": [],
        "value": "mceoin"
      },
      "story_text": {
        "fullyHighlighted": false,
        "matchLevel": "full",
        "matchedWords": [
          "ai",
          "agents",
          "business",
          "execution"
        ],
        "value": "Hi HN, I’m Eoin, founder of Sourcetable (<a href=\"https://sourcetable.com\" rel=\"nofollow\">https://sourcetable.com</a>).<p>Today, we’re launching Superagents. You can now connect your spreadsheet to any database, API or MCP server on the Internet. All of that data is available inside your spreadsheet, and you can use <em>AI</em> to analyze it and build models, reports and visualizations.<p>The reason I started the company is because I spent 10 years at startups across engineering and operations roles and realized that Excel and Sheets weren't architected for the modern information environment. This creates a tremendous amount of nuisance and busywork cobbling together SaaS tools, reporting suites, and the misery of endless coordination meetings to make it all happen. (Boo meetings!)<p>Spreadsheets aren’t just a <em>business</em> application: they’re the original thinking tool. The quality of these tools has a downstream impact on analytical thinking and creativity writ large, so this is a problem worth solving. Fast forward to today, we’re a 6 person team taking on Excel, Sheets and ChatGPT, so we’re excited to hear what you think!<p>Who are Superagents for?\nAnalysts, operators, and anyone doing data-centric work in spreadsheets. We see a tonne of finance people, of course, but also students, researchers and mom &amp; pop shops. Sourcetable's superagents democratize data access and analysis, which is nice because our company’s mission is to make data accessible to everyone.<p>Why “Superagents”? \nBecause they can plan and orchestrate other task-specific <em>agents</em> to complete your work for you. We have a lot of different <em>AI</em> tools and <em>agents</em> inside Sourcetable, but there’s a whole lot more on the Agentic Web. Superagents are like the conductor that coordinates them all and calls on them when needed. Also, it’s a fun feature name (thanks, Alyssa!)<p>If you remember the linked-data dream of the semantic web movement, that future is now: all of your <em>business</em> data is available and connected in Sourcetable.<p>How does it work?\nSourcetable is running a python virtual machine under the hood. Everything is sandboxed, and there are hundreds of <em>AI</em> tools and libraries our <em>AI</em> can access. Superagents are also doing code-gen on the fly to solve problems. The closest system we have found is Replit’s sandboxed operating systems. Beyond that Mixtral, ChatGPT and Anthropic offer some limited data connectivity features, except these <em>AI</em> chat services lack the storage, compute, and code <em>execution</em> that Sourcetable and Replit provide. This is all very new.<p>How is this different to your previous data connectors, etc? \nWe started out using ETL services to sync data and provide a GUI-driven PowerBI like experience in your spreadsheet. This was useful for people who knew SQL and how to write joins to combine fragmented data, but for everyone else (read: practically everyone), this solution just didn’t provide the frictionless, self-serve experience that we wanted.<p>Our choices were to switch the GTM motion or change the product, so we shelved that reporting suite and focused on our <em>AI</em> spreadsheet and waited for models to catch up with our ambitions. Now that they have, we’re re-launching Sourcetable with our original goal in mind: building a spreadsheet-based operating system for the Agent Web, with fully networked data access for <i>everyone</i> on your team.<p><em>AI</em> is the great UX enabler.<p>Caveats:<p>* We heavily use Postgres, Google Analytics, Stripe and Google Search Console with Superagents.<p>* We haven’t tested every endpoint on the Internet. We find that mainstream, well documented applications work best.<p>* Yes, you can write data back to 3rd party applications and databases. We generally advise against this unless you understand the risks involved in giving <em>AI</em> write-access to your data.<p>Bonus round:<p>* All data connectors added during this launch week are FREE. (Regular <em>AI</em> messaging limits still apply.)<p>Product Feedback?\neoin@sourcetable.com"
      },
      "title": {
        "matchLevel": "none",
        "matchedWords": [],
        "value": "Show HN: Superagents – connect spreadsheets to any database, API or MCP server"
      },
      "url": {
        "matchLevel": "none",
        "matchedWords": [],
        "value": "https://sourcetable.com/superagents"
      }
    },
    "_tags": [
      "story",
      "author_mceoin",
      "story_45186904",
      "show_hn"
    ],
    "author": "mceoin",
    "children": [
      45187116,
      45191577,
      45187372,
      45189407,
      45191634,
      45193184,
      45191690,
      45187200,
      45207752
    ],
    "created_at": "2025-09-09T18:55:35Z",
    "created_at_i": 1757444135,
    "num_comments": 13,
    "objectID": "45186904",
    "points": 35,
    "story_id": 45186904,
    "story_text": "Hi HN, I’m Eoin, founder of Sourcetable (<a href=\"https:&#x2F;&#x2F;sourcetable.com\" rel=\"nofollow\">https:&#x2F;&#x2F;sourcetable.com</a>).<p>Today, we’re launching Superagents. You can now connect your spreadsheet to any database, API or MCP server on the Internet. All of that data is available inside your spreadsheet, and you can use AI to analyze it and build models, reports and visualizations.<p>The reason I started the company is because I spent 10 years at startups across engineering and operations roles and realized that Excel and Sheets weren&#x27;t architected for the modern information environment. This creates a tremendous amount of nuisance and busywork cobbling together SaaS tools, reporting suites, and the misery of endless coordination meetings to make it all happen. (Boo meetings!)<p>Spreadsheets aren’t just a business application: they’re the original thinking tool. The quality of these tools has a downstream impact on analytical thinking and creativity writ large, so this is a problem worth solving. Fast forward to today, we’re a 6 person team taking on Excel, Sheets and ChatGPT, so we’re excited to hear what you think!<p>Who are Superagents for?\nAnalysts, operators, and anyone doing data-centric work in spreadsheets. We see a tonne of finance people, of course, but also students, researchers and mom &amp; pop shops. Sourcetable&#x27;s superagents democratize data access and analysis, which is nice because our company’s mission is to make data accessible to everyone.<p>Why “Superagents”? \nBecause they can plan and orchestrate other task-specific agents to complete your work for you. We have a lot of different AI tools and agents inside Sourcetable, but there’s a whole lot more on the Agentic Web. Superagents are like the conductor that coordinates them all and calls on them when needed. Also, it’s a fun feature name (thanks, Alyssa!)<p>If you remember the linked-data dream of the semantic web movement, that future is now: all of your business data is available and connected in Sourcetable.<p>How does it work?\nSourcetable is running a python virtual machine under the hood. Everything is sandboxed, and there are hundreds of AI tools and libraries our AI can access. Superagents are also doing code-gen on the fly to solve problems. The closest system we have found is Replit’s sandboxed operating systems. Beyond that Mixtral, ChatGPT and Anthropic offer some limited data connectivity features, except these AI chat services lack the storage, compute, and code execution that Sourcetable and Replit provide. This is all very new.<p>How is this different to your previous data connectors, etc? \nWe started out using ETL services to sync data and provide a GUI-driven PowerBI like experience in your spreadsheet. This was useful for people who knew SQL and how to write joins to combine fragmented data, but for everyone else (read: practically everyone), this solution just didn’t provide the frictionless, self-serve experience that we wanted.<p>Our choices were to switch the GTM motion or change the product, so we shelved that reporting suite and focused on our AI spreadsheet and waited for models to catch up with our ambitions. Now that they have, we’re re-launching Sourcetable with our original goal in mind: building a spreadsheet-based operating system for the Agent Web, with fully networked data access for <i>everyone</i> on your team.<p>AI is the great UX enabler.<p>Caveats:<p>* We heavily use Postgres, Google Analytics, Stripe and Google Search Console with Superagents.<p>* We haven’t tested every endpoint on the Internet. We find that mainstream, well documented applications work best.<p>* Yes, you can write data back to 3rd party applications and databases. We generally advise against this unless you understand the risks involved in giving AI write-access to your data.<p>Bonus round:<p>* All data connectors added during this launch week are FREE. (Regular AI messaging limits still apply.)<p>Product Feedback?\neoin@sourcetable.com",
    "title": "Show HN: Superagents – connect spreadsheets to any database, API or MCP server",
    "updated_at": "2025-09-11T18:11:15Z",
    "url": "https://sourcetable.com/superagents",
    "hn_url": "https://news.ycombinator.com/item?id=45186904",
    "comments": 13,
    "query": "AI agents business execution",
    "score": 48
  },
  {
    "_highlightResult": {
      "author": {
        "matchLevel": "none",
        "matchedWords": [],
        "value": "mahdiyar"
      },
      "story_text": {
        "fullyHighlighted": false,
        "matchLevel": "full",
        "matchedWords": [
          "ai",
          "agents",
          "business",
          "execution"
        ],
        "value": "Hey HN,\n  Last week, I spent 40 minutes debugging a production issue that should have taken 5. Not because the bug was complex, but because I kept switching between Claude Code, Cursor, Codex, and\n   Gemini - copying context, losing thread, starting over.<p><pre><code>  The workflow was painful:\n  1. Claude Code couldn't reproduce a React rendering bug\n  2. Copy-pasted 200 lines to Cursor - different answer, still wrong\n  3. Tried Codex - needed to re-explain the database schema\n  4. Finally Gemini spotted it, but I'd lost the original error logs\n\n  This context-switching tax happens weekly. So I built Roundtable <em>AI</em> MCP Server.\n\n\n\n</code></pre>\nWhat makes it different: Unlike existing multi-<em>agent</em> tools that require custom APIs or complex setup, Roundtable works with your existing <em>AI</em> CLI tools through the Model Context Protocol. Zero configuration - it auto-discovers what's installed and just works.\n  Architecture: Your IDE → MCP Server → Multiple <em>AI</em> CLIs (parallel <em>execution</em>)\nIt runs CLI Coding <em>Agents</em> in headless mode and shares the results with the LLM of choice.\nReal examples I use daily:<p><pre><code>  Example 1 - Parallel Code Review:\n  Claude Code &gt; Run Gemini, Codex, Cursor and Claude Code Subagent in parallel and task them to review my landing page at '@frontend/src/app/roundtable/page.tsx'\n\n  → Gemini: React performance, component architecture, UX patterns\n  → Codex: Code quality, TypeScript usage, best practices\n  → Cursor: Accessibility, SEO optimization, modern web standards\n  → Claude: <em>Business</em> logic, user flow, conversion optimization\n\n  Save their review in {subagent_name}_review.md then aggregate their feedback\n\n  Example 2 - Sequential Task Delegation:\n  First: Assign Gemini Subagent to summarize the logic of '@server.py'\n  Then: Send summary to Codex Subagent to implement Feature X from 'feature_x_spec.md'\n  Finally: I run the code and provide feedback to Codex until all tests in 'test_cases.py' pass\n  (Tests hidden from Codex to avoid overfitting)\n\n  Example 3 - Specialized Debugging:\n  Assign Cursor with GPT-5 and Cursor with Claude-4-thinking to debug issues in 'server.py'\n  Here's the production log: [memory leak stacktrace]\n  Create comprehensive fix plan with root cause analysis\n\n  All run in parallel with shared project context. Takes 2-5 minutes vs 20+ minutes of manual copy-paste coordination.\n\n</code></pre>\nTry it: pip install roundtable-<em>ai</em> roundtable-<em>ai</em> --check # Shows which <em>AI</em> tools you have\n  I'd love feedback on:\n  1. Which <em>AI</em> combinations work best for your debugging workflows?\n  2. Any IDE integration pain points?\n  3. Team adoption blockers I should address?<p><pre><code>  GitHub: [https://github.com/askbudi/roundtable](https://github.com/askbudi/roundtable)\n  Website: [https://askbudi.<em>ai</em>/roundtable](https://askbudi.<em>ai</em>/roundtable)</code></pre>"
      },
      "title": {
        "matchLevel": "none",
        "matchedWords": [],
        "value": "Show HN: Roundtable MCP, Orchestrate Claude Code, Cursor, Gemini and Codex"
      },
      "url": {
        "matchLevel": "none",
        "matchedWords": [],
        "value": "https://github.com/askbudi/roundtable"
      }
    },
    "_tags": [
      "story",
      "author_mahdiyar",
      "story_45374908",
      "show_hn"
    ],
    "author": "mahdiyar",
    "children": [
      45375769,
      45392394,
      45377001
    ],
    "created_at": "2025-09-25T16:27:27Z",
    "created_at_i": 1758817647,
    "num_comments": 3,
    "objectID": "45374908",
    "points": 2,
    "story_id": 45374908,
    "story_text": "Hey HN,\n  Last week, I spent 40 minutes debugging a production issue that should have taken 5. Not because the bug was complex, but because I kept switching between Claude Code, Cursor, Codex, and\n   Gemini - copying context, losing thread, starting over.<p><pre><code>  The workflow was painful:\n  1. Claude Code couldn&#x27;t reproduce a React rendering bug\n  2. Copy-pasted 200 lines to Cursor - different answer, still wrong\n  3. Tried Codex - needed to re-explain the database schema\n  4. Finally Gemini spotted it, but I&#x27;d lost the original error logs\n\n  This context-switching tax happens weekly. So I built Roundtable AI MCP Server.\n\n\n\n</code></pre>\nWhat makes it different: Unlike existing multi-agent tools that require custom APIs or complex setup, Roundtable works with your existing AI CLI tools through the Model Context Protocol. Zero configuration - it auto-discovers what&#x27;s installed and just works.\n  Architecture: Your IDE → MCP Server → Multiple AI CLIs (parallel execution)\nIt runs CLI Coding Agents in headless mode and shares the results with the LLM of choice.\nReal examples I use daily:<p><pre><code>  Example 1 - Parallel Code Review:\n  Claude Code &gt; Run Gemini, Codex, Cursor and Claude Code Subagent in parallel and task them to review my landing page at &#x27;@frontend&#x2F;src&#x2F;app&#x2F;roundtable&#x2F;page.tsx&#x27;\n\n  → Gemini: React performance, component architecture, UX patterns\n  → Codex: Code quality, TypeScript usage, best practices\n  → Cursor: Accessibility, SEO optimization, modern web standards\n  → Claude: Business logic, user flow, conversion optimization\n\n  Save their review in {subagent_name}_review.md then aggregate their feedback\n\n  Example 2 - Sequential Task Delegation:\n  First: Assign Gemini Subagent to summarize the logic of &#x27;@server.py&#x27;\n  Then: Send summary to Codex Subagent to implement Feature X from &#x27;feature_x_spec.md&#x27;\n  Finally: I run the code and provide feedback to Codex until all tests in &#x27;test_cases.py&#x27; pass\n  (Tests hidden from Codex to avoid overfitting)\n\n  Example 3 - Specialized Debugging:\n  Assign Cursor with GPT-5 and Cursor with Claude-4-thinking to debug issues in &#x27;server.py&#x27;\n  Here&#x27;s the production log: [memory leak stacktrace]\n  Create comprehensive fix plan with root cause analysis\n\n  All run in parallel with shared project context. Takes 2-5 minutes vs 20+ minutes of manual copy-paste coordination.\n\n</code></pre>\nTry it: pip install roundtable-ai roundtable-ai --check # Shows which AI tools you have\n  I&#x27;d love feedback on:\n  1. Which AI combinations work best for your debugging workflows?\n  2. Any IDE integration pain points?\n  3. Team adoption blockers I should address?<p><pre><code>  GitHub: [https:&#x2F;&#x2F;github.com&#x2F;askbudi&#x2F;roundtable](https:&#x2F;&#x2F;github.com&#x2F;askbudi&#x2F;roundtable)\n  Website: [https:&#x2F;&#x2F;askbudi.ai&#x2F;roundtable](https:&#x2F;&#x2F;askbudi.ai&#x2F;roundtable)</code></pre>",
    "title": "Show HN: Roundtable MCP, Orchestrate Claude Code, Cursor, Gemini and Codex",
    "updated_at": "2025-10-07T17:43:07Z",
    "url": "https://github.com/askbudi/roundtable",
    "hn_url": "https://news.ycombinator.com/item?id=45374908",
    "comments": 3,
    "query": "AI agents business execution",
    "score": 5
  },
  {
    "_highlightResult": {
      "author": {
        "matchLevel": "none",
        "matchedWords": [],
        "value": "samkaru"
      },
      "story_text": {
        "matchLevel": "none",
        "matchedWords": [],
        "value": "Hey HN!<p>My co-founder and I have been building Logical, a proactive desktop AI copilot that watches what you're doing (locally), understands the context of your workflow, and surfaces helpful actions before you prompt it.<p>- Quick demo: <a href=\"https://www.loom.com/share/090a065315934aa7b36a7676f9394d1f\" rel=\"nofollow\">https://www.loom.com/share/090a065315934aa7b36a7676f9394d1f</a><p>- Try Logical: <a href=\"https://trylogical.ai/signup\">https://trylogical.ai/signup</a><p>Logical lives on your desktop, infers what you're trying to do across apps – email, meetings, documents, PDFs, terminals – and:<p>- Gives you a reply suggestion when you hit &quot;Reply&quot; on an email thread<p>- Offers to &quot;Check schedule&quot; when you open a message asking for a quick chat<p>- Automatically extracts to-dos during calls and from pretty much anywhere on your screen (and reminds you to follow-up)<p>- Suggests a formula in Excel as you work that you can apply with one click<p>- Explains terms of research papers as you highlight them<p>No prompting. No switching context. No copying text around.<p>* Why we built this *<p>Despite big progress in LLMs, the dominant UX is still: User does work –&gt; realizes AI could help –&gt; stops –&gt; writes a prompt.<p>But your computer already has the context of what you're doing. It knows what window you're in, what text you're reading, which script just errored, and what meeting you're sitting in. We wanted an AI that uses this ambient context to proactively assist – more like a real teammate than a chatbot.<p>* Privacy and data handling (something we deeply care about) *<p>Right now:<p>- We offer a technical guarantee that no user data ever touches Logical servers.<p>- Context is sanitized locally (our local pipeline strips PII / sensitive text before anything is sent off).<p>Long-term, we aim to move everything on-device as small language models and consumer AI chips mature.<p>We've seen interest from founders, researchers, engineers, and privacy-sensitive users who want AI benefits without cloud exposure.<p>* What's under the hood *<p>- A context engine that digests signals and user data from apps (both local, and if you choose, cloud-based services).<p>- A sanitization pipeline that removes identifiable or sensitive details before model usage.<p>- A local vector store + lightweight knowledge graph for immediate retrieval.<p>- An intent engine that infers &quot;what you're trying to do&quot; in real time and surfaces actions at the right moment.<p>* What's next *<p>- Windows support. Logical is currently Mac only.<p>- Letting developers plug into the context engine and intent engine to offer richer experiences on their apps. At least until desktop MCP is good enough.<p>- Fine-tuned integrations with more apps and workflows.<p>Would love your feedback:<p>If you're interested in: proactive AI; OS-level context awareness; on-device AI; privacy-preserving AI; building AI that actually reduces friction instead of adding more prompts<p>Happy to chat in the comments! hello@trylogical.ai is always open for feedback."
      },
      "title": {
        "matchLevel": "none",
        "matchedWords": [],
        "value": "Show HN: Logical (YC F25): a local-first proactive desktop AI copilot"
      },
      "url": {
        "matchLevel": "none",
        "matchedWords": [],
        "value": "https://trylogical.ai"
      }
    },
    "_tags": [
      "story",
      "author_samkaru",
      "story_46061813",
      "show_hn"
    ],
    "author": "samkaru",
    "created_at": "2025-11-26T20:11:05Z",
    "created_at_i": 1764187865,
    "num_comments": 0,
    "objectID": "46061813",
    "points": 8,
    "story_id": 46061813,
    "story_text": "Hey HN!<p>My co-founder and I have been building Logical, a proactive desktop AI copilot that watches what you&#x27;re doing (locally), understands the context of your workflow, and surfaces helpful actions before you prompt it.<p>- Quick demo: <a href=\"https:&#x2F;&#x2F;www.loom.com&#x2F;share&#x2F;090a065315934aa7b36a7676f9394d1f\" rel=\"nofollow\">https:&#x2F;&#x2F;www.loom.com&#x2F;share&#x2F;090a065315934aa7b36a7676f9394d1f</a><p>- Try Logical: <a href=\"https:&#x2F;&#x2F;trylogical.ai&#x2F;signup\">https:&#x2F;&#x2F;trylogical.ai&#x2F;signup</a><p>Logical lives on your desktop, infers what you&#x27;re trying to do across apps – email, meetings, documents, PDFs, terminals – and:<p>- Gives you a reply suggestion when you hit &quot;Reply&quot; on an email thread<p>- Offers to &quot;Check schedule&quot; when you open a message asking for a quick chat<p>- Automatically extracts to-dos during calls and from pretty much anywhere on your screen (and reminds you to follow-up)<p>- Suggests a formula in Excel as you work that you can apply with one click<p>- Explains terms of research papers as you highlight them<p>No prompting. No switching context. No copying text around.<p>* Why we built this *<p>Despite big progress in LLMs, the dominant UX is still: User does work –&gt; realizes AI could help –&gt; stops –&gt; writes a prompt.<p>But your computer already has the context of what you&#x27;re doing. It knows what window you&#x27;re in, what text you&#x27;re reading, which script just errored, and what meeting you&#x27;re sitting in. We wanted an AI that uses this ambient context to proactively assist – more like a real teammate than a chatbot.<p>* Privacy and data handling (something we deeply care about) *<p>Right now:<p>- We offer a technical guarantee that no user data ever touches Logical servers.<p>- Context is sanitized locally (our local pipeline strips PII &#x2F; sensitive text before anything is sent off).<p>Long-term, we aim to move everything on-device as small language models and consumer AI chips mature.<p>We&#x27;ve seen interest from founders, researchers, engineers, and privacy-sensitive users who want AI benefits without cloud exposure.<p>* What&#x27;s under the hood *<p>- A context engine that digests signals and user data from apps (both local, and if you choose, cloud-based services).<p>- A sanitization pipeline that removes identifiable or sensitive details before model usage.<p>- A local vector store + lightweight knowledge graph for immediate retrieval.<p>- An intent engine that infers &quot;what you&#x27;re trying to do&quot; in real time and surfaces actions at the right moment.<p>* What&#x27;s next *<p>- Windows support. Logical is currently Mac only.<p>- Letting developers plug into the context engine and intent engine to offer richer experiences on their apps. At least until desktop MCP is good enough.<p>- Fine-tuned integrations with more apps and workflows.<p>Would love your feedback:<p>If you&#x27;re interested in: proactive AI; OS-level context awareness; on-device AI; privacy-preserving AI; building AI that actually reduces friction instead of adding more prompts<p>Happy to chat in the comments! hello@trylogical.ai is always open for feedback.",
    "title": "Show HN: Logical (YC F25): a local-first proactive desktop AI copilot",
    "updated_at": "2025-11-27T05:28:07Z",
    "url": "https://trylogical.ai",
    "hn_url": "https://news.ycombinator.com/item?id=46061813",
    "comments": 0,
    "query": "AI founder workflows automation",
    "score": 8
  },
  {
    "_highlightResult": {
      "author": {
        "matchLevel": "none",
        "matchedWords": [],
        "value": "a6kme"
      },
      "story_text": {
        "matchLevel": "none",
        "matchedWords": [],
        "value": "Hi HN, I have been building voice agents for sometime now. I was earlier automating parts of visa processing, and we needed real-time, multilingual voice calling.<p>I assumed the hard work was just wiring LiveKit/Pipecat + STT/TTS + an LLM. It wasn’t.<p>Even with solid OSS (Pipecat/LiveKit), we still had to do a lot of plumbing-  variable extraction, tracing, testing etc and any workflow changes required constant redeploys.<p>We eventually realized we’d spent more time building infrastructure than building the actual agents. Everything felt custom. We hit every possible pain with Pipecat and VAPI style systems.<p>So we built Dograh - a fully open-source voice agent framework that includes all the boring, painful pieces by default.<p>What’s different:<p>- Pipecat-based engine, but forked - custom event model, and concurrency fixes<p>- One-click start template generated by an LLM Agent for a quick get start template for any use case<p>- Drag-and-drop visual agent builder for quick iteration (the thing we wished existed earlier)<p>- Variable extraction layer (name/order/date/etc.) baked into the LLM loop<p>- Built in Telephony integration (Twilio/ Vonage/ Vobiz/ Cloudonix)<p>- Multilingual support end-to-end<p>- Select any LLM TTS STT (add their credits, if any)<p>- AI-to-AI call testing: automatically stress-test an agent before shipping (still a work in progress- so patchy as of now)<p>- Fully Open Source<p>It's built and maintained by YC alumni / exit founders who got tired of rebuilding the same plumbing.<p>Why we open-sourced it:\nWe kept feeling that the space was drifting toward closed SaaS abstractions (VAPI, Retell). Those are good for demos, but once you need data controls, privacy or self/offline deployment, you end up stuck. We wanted a stack where you can see every part, fork it, self-host it, and patch it as needed.<p>Try it:<p>- Repo: <a href=\"https://github.com/dograh-hq/dograh\" rel=\"nofollow\">https://github.com/dograh-hq/dograh</a><p>This spins up a basic multilingual agent  with everything pre-wired.<p>Who this is for:<p>- If you are looking for self hosting a Vapi like platform for Data Privacy etc.<p>- Anyone trying to build production-grade voice agents without reinventing audio plumbing.<p>- If you’ve tried to glue STT→LLM→TTS manually, you probably know the exact pain this is built for<p>Happy to answer technical questions, show the architecture, or hear how we can improve the product."
      },
      "title": {
        "matchLevel": "none",
        "matchedWords": [],
        "value": "Show HN: Dograh – an OSS Vapi alternative to quickly build and test voice agents"
      },
      "url": {
        "matchLevel": "none",
        "matchedWords": [],
        "value": "https://github.com/dograh-hq/dograh"
      }
    },
    "_tags": [
      "story",
      "author_a6kme",
      "story_46189836",
      "show_hn"
    ],
    "author": "a6kme",
    "children": [
      46189953,
      46189900,
      46270202,
      46270222,
      46270751,
      46270301
    ],
    "created_at": "2025-12-08T08:35:24Z",
    "created_at_i": 1765182924,
    "num_comments": 10,
    "objectID": "46189836",
    "points": 16,
    "story_id": 46189836,
    "story_text": "Hi HN, I have been building voice agents for sometime now. I was earlier automating parts of visa processing, and we needed real-time, multilingual voice calling.<p>I assumed the hard work was just wiring LiveKit&#x2F;Pipecat + STT&#x2F;TTS + an LLM. It wasn’t.<p>Even with solid OSS (Pipecat&#x2F;LiveKit), we still had to do a lot of plumbing-  variable extraction, tracing, testing etc and any workflow changes required constant redeploys.<p>We eventually realized we’d spent more time building infrastructure than building the actual agents. Everything felt custom. We hit every possible pain with Pipecat and VAPI style systems.<p>So we built Dograh - a fully open-source voice agent framework that includes all the boring, painful pieces by default.<p>What’s different:<p>- Pipecat-based engine, but forked - custom event model, and concurrency fixes<p>- One-click start template generated by an LLM Agent for a quick get start template for any use case<p>- Drag-and-drop visual agent builder for quick iteration (the thing we wished existed earlier)<p>- Variable extraction layer (name&#x2F;order&#x2F;date&#x2F;etc.) baked into the LLM loop<p>- Built in Telephony integration (Twilio&#x2F; Vonage&#x2F; Vobiz&#x2F; Cloudonix)<p>- Multilingual support end-to-end<p>- Select any LLM TTS STT (add their credits, if any)<p>- AI-to-AI call testing: automatically stress-test an agent before shipping (still a work in progress- so patchy as of now)<p>- Fully Open Source<p>It&#x27;s built and maintained by YC alumni &#x2F; exit founders who got tired of rebuilding the same plumbing.<p>Why we open-sourced it:\nWe kept feeling that the space was drifting toward closed SaaS abstractions (VAPI, Retell). Those are good for demos, but once you need data controls, privacy or self&#x2F;offline deployment, you end up stuck. We wanted a stack where you can see every part, fork it, self-host it, and patch it as needed.<p>Try it:<p>- Repo: <a href=\"https:&#x2F;&#x2F;github.com&#x2F;dograh-hq&#x2F;dograh\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;dograh-hq&#x2F;dograh</a><p>This spins up a basic multilingual agent  with everything pre-wired.<p>Who this is for:<p>- If you are looking for self hosting a Vapi like platform for Data Privacy etc.<p>- Anyone trying to build production-grade voice agents without reinventing audio plumbing.<p>- If you’ve tried to glue STT→LLM→TTS manually, you probably know the exact pain this is built for<p>Happy to answer technical questions, show the architecture, or hear how we can improve the product.",
    "title": "Show HN: Dograh – an OSS Vapi alternative to quickly build and test voice agents",
    "updated_at": "2025-12-28T09:32:54Z",
    "url": "https://github.com/dograh-hq/dograh",
    "hn_url": "https://news.ycombinator.com/item?id=46189836",
    "comments": 10,
    "query": "AI founder workflows automation",
    "score": 26
  },
  {
    "_highlightResult": {
      "author": {
        "matchLevel": "none",
        "matchedWords": [],
        "value": "Mrakermo"
      },
      "story_text": {
        "fullyHighlighted": false,
        "matchLevel": "partial",
        "matchedWords": [
          "ai",
          "workflows"
        ],
        "value": "Hi HN,<p>I’m Eric, and I built www.meetgoran.com<p>Goran is a Mac/Windows desktop app for sales teams that turns your calls into actionable coaching: what was covered (and what wasn’t), what to improve next time, and patterns across reps.<p>First 5 meetings free (no credit card) ~ 10 min setup.<p>Connect Google Calendar so it can join scheduled meetings and capture the call context<p>What it does (practical, not “<em>AI</em> magic”):<p>- Produces structured sales notes + highlights key moments (pricing pushback, next steps, etc.)<p>- Scores calls against frameworks like MEDDIC/BANT (or your own checklist)<p>- Helps managers compare “top vs median” behaviors without rewatching hours of recordings<p>- Makes good examples searchable so new reps can copy what’s already working<p>Why I built it:<p>In most teams, the best talk-tracks stay trapped in recordings nobody rewatches, and managers don’t have time to coach every rep. I wanted something that turns calls into a “self-building playbook” reps will actually use.<p>What I’d love feedback on:<p>- Where would this not fit (team size, <em>workflow</em>, compliance constraints)?<p>- What should be the “default” output: rep coaching, manager dashboard, or team playbook?<p>Super happy with all responses."
      },
      "title": {
        "fullyHighlighted": false,
        "matchLevel": "partial",
        "matchedWords": [
          "founder",
          "automation"
        ],
        "value": "Show HN: <em>Automati</em>cally build sales playbook. For <em>founders</em> doing sales"
      }
    },
    "_tags": [
      "story",
      "author_Mrakermo",
      "story_46710688",
      "show_hn"
    ],
    "author": "Mrakermo",
    "children": [
      46713720
    ],
    "created_at": "2026-01-21T19:53:35Z",
    "created_at_i": 1769025215,
    "num_comments": 1,
    "objectID": "46710688",
    "points": 9,
    "story_id": 46710688,
    "story_text": "Hi HN,<p>I’m Eric, and I built www.meetgoran.com<p>Goran is a Mac&#x2F;Windows desktop app for sales teams that turns your calls into actionable coaching: what was covered (and what wasn’t), what to improve next time, and patterns across reps.<p>First 5 meetings free (no credit card) ~ 10 min setup.<p>Connect Google Calendar so it can join scheduled meetings and capture the call context<p>What it does (practical, not “AI magic”):<p>- Produces structured sales notes + highlights key moments (pricing pushback, next steps, etc.)<p>- Scores calls against frameworks like MEDDIC&#x2F;BANT (or your own checklist)<p>- Helps managers compare “top vs median” behaviors without rewatching hours of recordings<p>- Makes good examples searchable so new reps can copy what’s already working<p>Why I built it:<p>In most teams, the best talk-tracks stay trapped in recordings nobody rewatches, and managers don’t have time to coach every rep. I wanted something that turns calls into a “self-building playbook” reps will actually use.<p>What I’d love feedback on:<p>- Where would this not fit (team size, workflow, compliance constraints)?<p>- What should be the “default” output: rep coaching, manager dashboard, or team playbook?<p>Super happy with all responses.",
    "title": "Show HN: Automatically build sales playbook. For founders doing sales",
    "updated_at": "2026-01-23T05:53:19Z",
    "url": "",
    "hn_url": "https://news.ycombinator.com/item?id=46710688",
    "comments": 1,
    "query": "AI founder workflows automation",
    "score": 10
  },
  {
    "_highlightResult": {
      "author": {
        "matchLevel": "none",
        "matchedWords": [],
        "value": "ljhskyso7"
      },
      "story_text": {
        "fullyHighlighted": false,
        "matchLevel": "full",
        "matchedWords": [
          "ai",
          "founder",
          "workflows",
          "automation"
        ],
        "value": "Hi HN — I’m Kimi, <em>founder</em> of Aident <em>AI</em>.<p>A couple years ago, I cold-started a startup and tried to automate my outreach pipeline with a patchwork: RPA + Zapier + &quot;just some ChatGPT&quot;.<p>It worked… until it didn’t. Every time I tweaked the strategy, the <em>automation</em> snapped. The system wasn’t built for change — it was built for wiring.<p>And that’s when it hit me: <em>AI</em> is finally smart enough to do real work, but we still don’t have a clean way to communicate the work to it: Drag-and-drop flows are too rigid; Scripts are too fragile; Prompts are too ephemeral. I kept thinking: why can’t <em>automation</em> be something you can simply read, edit, and trust?<p>So we built Aident around one idea: the source of truth is a document.<p>You write a Playbook in plain English (objectives, roles, handoffs), Aiden helps refine it, then we compile it into a reliable agent team (with built-in PM + QA roles) that executes skills with your 250+ tools (Gmail, Slack, Notion, Google Sheets/Calendar, GitHub, etc.). You can test it, schedule it, and then forget about it - it will keep delivering, even when you sleep.<p>It’s still early beta and can be bumpy sometimes, but I’d really appreciate you give it a try and let me know your feedbacks:<p>What <em>workflow</em> would you try first?\nWhere would this be a bad fit (compliance, data sensitivity, team size)?\nWhat would make you trust it enough to run unattended?<p>Try @ <a href=\"https://app.aident.ai\" rel=\"nofollow\">https://app.aident.<em>ai</em></a>"
      },
      "title": {
        "fullyHighlighted": false,
        "matchLevel": "partial",
        "matchedWords": [
          "automation"
        ],
        "value": "Show HN: Aident, agentic <em>automations</em> as plain-English playbooks"
      },
      "url": {
        "fullyHighlighted": false,
        "matchLevel": "partial",
        "matchedWords": [
          "ai"
        ],
        "value": "https://aident.<em>ai</em>/"
      }
    },
    "_tags": [
      "story",
      "author_ljhskyso7",
      "story_46715824",
      "show_hn"
    ],
    "author": "ljhskyso7",
    "created_at": "2026-01-22T06:04:02Z",
    "created_at_i": 1769061842,
    "num_comments": 0,
    "objectID": "46715824",
    "points": 4,
    "story_id": 46715824,
    "story_text": "Hi HN — I’m Kimi, founder of Aident AI.<p>A couple years ago, I cold-started a startup and tried to automate my outreach pipeline with a patchwork: RPA + Zapier + &quot;just some ChatGPT&quot;.<p>It worked… until it didn’t. Every time I tweaked the strategy, the automation snapped. The system wasn’t built for change — it was built for wiring.<p>And that’s when it hit me: AI is finally smart enough to do real work, but we still don’t have a clean way to communicate the work to it: Drag-and-drop flows are too rigid; Scripts are too fragile; Prompts are too ephemeral. I kept thinking: why can’t automation be something you can simply read, edit, and trust?<p>So we built Aident around one idea: the source of truth is a document.<p>You write a Playbook in plain English (objectives, roles, handoffs), Aiden helps refine it, then we compile it into a reliable agent team (with built-in PM + QA roles) that executes skills with your 250+ tools (Gmail, Slack, Notion, Google Sheets&#x2F;Calendar, GitHub, etc.). You can test it, schedule it, and then forget about it - it will keep delivering, even when you sleep.<p>It’s still early beta and can be bumpy sometimes, but I’d really appreciate you give it a try and let me know your feedbacks:<p>What workflow would you try first?\nWhere would this be a bad fit (compliance, data sensitivity, team size)?\nWhat would make you trust it enough to run unattended?<p>Try @ <a href=\"https:&#x2F;&#x2F;app.aident.ai\" rel=\"nofollow\">https:&#x2F;&#x2F;app.aident.ai</a>",
    "title": "Show HN: Aident, agentic automations as plain-English playbooks",
    "updated_at": "2026-01-22T06:12:09Z",
    "url": "https://aident.ai/",
    "hn_url": "https://news.ycombinator.com/item?id=46715824",
    "comments": 0,
    "query": "AI founder workflows automation",
    "score": 4
  },
  {
    "_highlightResult": {
      "author": {
        "matchLevel": "none",
        "matchedWords": [],
        "value": "robeym"
      },
      "story_text": {
        "fullyHighlighted": false,
        "matchLevel": "full",
        "matchedWords": [
          "ai",
          "founder",
          "workflows",
          "automation"
        ],
        "value": "I'm a developer who built an ERP/CRM system for small manufacturers (https://www.paxerp.com). It does all the basics very well; financial reporting, lot tracking, production planning, shipping carrier integrations, the usual <em>workflow</em> stuff—but there's zero <em>AI</em> in it.\nIt's just fast, clean, and solves real problems I saw working in manufacturing ERP systems. The product works well, customers really like it, but I have almost no sales experience.<p>Every SaaS <em>founder</em> seems to be talking about &quot;<em>AI</em>-powered insights&quot; and &quot;intelligent <em>automation</em>.&quot; while... We just have a clean system that is fast and tries to stay out of the user's way.<p>For those who've sold B2B SaaS (especially to traditional industries like manufacturing):<p>- Is &quot;no <em>AI</em>&quot; actually a disadvantage, or does it not matter as much as I think?<p>- How do I communicate value when the value is &quot;it's simple and fast, and your data is highly accessible&quot; vs &quot;revolutionary <em>AI</em>&quot;?<p>- Should I be adding <em>AI</em> features just to check a marketing box, even if customers don't need them?<p>You can learn more about why I built this on the websites about page. But now I'm wondering if I'm fighting an uphill battle by not having the buzzwords everyone else does.<p>Any advice from founders who've been here?<p>TY"
      },
      "title": {
        "fullyHighlighted": false,
        "matchLevel": "partial",
        "matchedWords": [
          "ai"
        ],
        "value": "Ask HN: How to sell SaaS without <em>AI</em> features in 2026?"
      }
    },
    "_tags": [
      "story",
      "author_robeym",
      "story_47023609",
      "ask_hn"
    ],
    "author": "robeym",
    "children": [
      47023748,
      47023877,
      47023657
    ],
    "created_at": "2026-02-15T13:45:28Z",
    "created_at_i": 1771163128,
    "num_comments": 4,
    "objectID": "47023609",
    "points": 1,
    "story_id": 47023609,
    "story_text": "I&#x27;m a developer who built an ERP&#x2F;CRM system for small manufacturers (https:&#x2F;&#x2F;www.paxerp.com). It does all the basics very well; financial reporting, lot tracking, production planning, shipping carrier integrations, the usual workflow stuff—but there&#x27;s zero AI in it.\nIt&#x27;s just fast, clean, and solves real problems I saw working in manufacturing ERP systems. The product works well, customers really like it, but I have almost no sales experience.<p>Every SaaS founder seems to be talking about &quot;AI-powered insights&quot; and &quot;intelligent automation.&quot; while... We just have a clean system that is fast and tries to stay out of the user&#x27;s way.<p>For those who&#x27;ve sold B2B SaaS (especially to traditional industries like manufacturing):<p>- Is &quot;no AI&quot; actually a disadvantage, or does it not matter as much as I think?<p>- How do I communicate value when the value is &quot;it&#x27;s simple and fast, and your data is highly accessible&quot; vs &quot;revolutionary AI&quot;?<p>- Should I be adding AI features just to check a marketing box, even if customers don&#x27;t need them?<p>You can learn more about why I built this on the websites about page. But now I&#x27;m wondering if I&#x27;m fighting an uphill battle by not having the buzzwords everyone else does.<p>Any advice from founders who&#x27;ve been here?<p>TY",
    "title": "Ask HN: How to sell SaaS without AI features in 2026?",
    "updated_at": "2026-02-15T21:28:12Z",
    "url": "",
    "hn_url": "https://news.ycombinator.com/item?id=47023609",
    "comments": 4,
    "query": "AI founder workflows automation",
    "score": 5
  },
  {
    "_highlightResult": {
      "author": {
        "matchLevel": "none",
        "matchedWords": [],
        "value": "PrateekJ17"
      },
      "story_text": {
        "fullyHighlighted": false,
        "matchLevel": "full",
        "matchedWords": [
          "ai",
          "agents",
          "business",
          "execution"
        ],
        "value": "Hey HN,<p>We've been heads down building Coasty for the past few months and wanted to share a milestone, we just achieved state-of-the-art results on OSWorld, the most comprehensive benchmark for computer-use <em>agents</em>.\nFor those unfamiliar, OSWorld tests whether <em>AI</em> <em>agents</em> can actually use a computer the way a human does navigating real desktop environments, clicking through UIs, filling out forms, managing files across apps.<p>We're building an <em>agent</em> <em>execution</em> platform for computer-use <em>AI</em>. Think of it like Vercel but for <em>AI</em> <em>agents</em> that operate full desktop environments. You give Coasty a task, and it spins up a sandboxed environment where an <em>agent</em> can see the screen, move the mouse, type, and complete end-to-end workflows things like filing expenses, canceling subscriptions, filling out insurance forms, or navigating legacy enterprise software.\nWhy this matters<p>Most &quot;<em>AI</em> automation&quot; today is really just API glue between apps that have APIs. But the vast majority of <em>business</em> workflows still live in UIs that were designed for humans, healthcare portals, government forms, internal tools that will never get an API. Computer-use <em>agents</em> unlock automation for all of that.\nWhat's next<p>We're opening up early access. If you're dealing with painful, repetitive computer workflows (especially in healthcare, insurance, legal, or ops), we'd love to talk.<p>Happy to answer questions about our approach, the benchmark, or anything else."
      },
      "title": {
        "fullyHighlighted": false,
        "matchLevel": "partial",
        "matchedWords": [
          "ai",
          "agents"
        ],
        "value": "Show HN: Coasty.<em>ai</em> – We just hit SOTA on OSWorld (computer-use <em>agent</em> benchmark)"
      }
    },
    "_tags": [
      "story",
      "author_PrateekJ17",
      "story_47117621",
      "show_hn"
    ],
    "author": "PrateekJ17",
    "children": [
      47117667,
      47118111,
      47117628
    ],
    "created_at": "2026-02-23T03:13:02Z",
    "created_at_i": 1771816382,
    "num_comments": 3,
    "objectID": "47117621",
    "points": 2,
    "story_id": 47117621,
    "story_text": "Hey HN,<p>We&#x27;ve been heads down building Coasty for the past few months and wanted to share a milestone, we just achieved state-of-the-art results on OSWorld, the most comprehensive benchmark for computer-use agents.\nFor those unfamiliar, OSWorld tests whether AI agents can actually use a computer the way a human does navigating real desktop environments, clicking through UIs, filling out forms, managing files across apps.<p>We&#x27;re building an agent execution platform for computer-use AI. Think of it like Vercel but for AI agents that operate full desktop environments. You give Coasty a task, and it spins up a sandboxed environment where an agent can see the screen, move the mouse, type, and complete end-to-end workflows things like filing expenses, canceling subscriptions, filling out insurance forms, or navigating legacy enterprise software.\nWhy this matters<p>Most &quot;AI automation&quot; today is really just API glue between apps that have APIs. But the vast majority of business workflows still live in UIs that were designed for humans, healthcare portals, government forms, internal tools that will never get an API. Computer-use agents unlock automation for all of that.\nWhat&#x27;s next<p>We&#x27;re opening up early access. If you&#x27;re dealing with painful, repetitive computer workflows (especially in healthcare, insurance, legal, or ops), we&#x27;d love to talk.<p>Happy to answer questions about our approach, the benchmark, or anything else.",
    "title": "Show HN: Coasty.ai – We just hit SOTA on OSWorld (computer-use agent benchmark)",
    "updated_at": "2026-02-25T08:39:14Z",
    "url": "",
    "hn_url": "https://news.ycombinator.com/item?id=47117621",
    "comments": 3,
    "query": "AI agents business execution",
    "score": 5
  }
]
